# ---------- MiniGPT-4 -----------
minigpt4_vicuna-7b:
    num_beams: 1 #1
    temperature: 0.7 #1.0
    max_new_tokens: 512
    top_p: 0.9
    length_penalty: 2


minigpt4_vicuna-13b:
    num_beams: 1 #1
    temperature: 0.7 #1.0
    max_new_tokens: 512
    top_p: 0.9
    length_penalty: 2


minigpt4_llama_2:
    num_beams: 1 #1
    temperature: 0.7 #1.0
    max_new_tokens: 512
    top_p: 0.9
    length_penalty: 2


# ---------- MiniGPT-v2 ----------
minigpt_v2:
    num_beams: 1 #1
    temperature: 0.7 # 0.6
    max_new_tokens: 512
    inst_pre: "" # "" / "[vqa] " / "[grounding] describe this image in detail" / "[refer] " / "[detection] " / "[identify] what is this"
    top_p: 0.9
    length_penalty: 2

# ---------- BLIP2 -----------
blip2_flan-t5-xl:
    num_beams: 3 #5
    max_new_tokens: 512
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: False

blip2-opt-2.7b:
    num_beams: 3 #5
    max_new_tokens: 512
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: False

blip2-opt-6.7b:
    num_beams: 3 #5
    max_new_tokens: 512
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: True


# ---------- InstructBLIP -----------
instructblip_vicuna-7b:
    num_beams: 3 #5
    max_new_tokens: 512
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: True

instructblip_vicuna-13b:
    num_beams: 3 #5
    max_new_tokens: 512
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: True

instructblip_flan-t5-xl:
    num_beams: 3 #5
    max_length: 256
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: False

instructblip_flan-t5-xxl:
    num_beams: 3 #5
    max_length: 256
    top_p: 0.9
    top_k: 50
    temperature: 0.7 #1
    length_penalty: 2
    load_float16: True


# ---------- LLaVA-1.5 -----------
llava-1.5-7b:
    do_sample: True
    num_beams: 1 #1
    temperature: 0.7 #0.2
    top_p: 0.9
    top_k: 50
    length_penalty: 2
    max_new_tokens: 512
    load_8bit: False
    
llava-1.5-13b:
    do_sample: True
    num_beams: 1 #1
    temperature: 0.7 #0.2
    top_p: 0.9
    top_k: 50
    length_penalty: 2
    max_new_tokens: 512
    load_8bit: False


# ---------- Otter -----------
otter:
    load_bit: 'fp32' # bf16 / fp16 / fp32
    max_new_tokens: 512
    num_beams: 1 # 3
    temperature: 0.7 #0.2
    top_p: 0.9
    top_k: 50
    length_penalty: 2


# ---------- Qwen-VL -----------
qwen-vl-chat:
    max_new_tokens: 512

# ---------- Shikra -----------
shikra-7b:
    max_new_tokens: 512
    num_beams: 3 # 5
    temperature: 0.7
    top_p: 0.9
    length_penalty: 2
    mode: 'Advanced' # 'VQA' / 'Advanced'



# ---------- InternLM-XComposer-VL -----------
internlm-xcomposer-vl-7b:
    max_new_tokens: 512
    num_beams: 1 # 1
    temperature: 0.7
    top_p: 0.9
    length_penalty: 2

internlm-xcomposer2-vl-7b:
    max_new_tokens: 512


# ---------- Emu2-Chat -----------
emu2-chat:
    max_new_tokens: 512
    num_beams: 3 # 3
    temperature: 0.7
    top_k: 50
    top_p: 0.9
    length_penalty: 10 #5
    low_memory: True

# ---------- GLM-4V -----------
glm-4v-9b:
    max_new_tokens: 512
    # num_beams: 3 # 3
    # temperature: 0.7
    top_k: 1
    # top_p: 0.9
    # length_penalty: 10 #5
    # low_memory: True

# ---------- MiniCPM-Llama3-V-2_5 -----------

minicpm-llama3-v-2_5:
    max_new_tokens: 512
    num_beams: 3
    temperature: 0.7


# ---------- mPLUG-Owl2 -----------
mplug-owl2:
    max_new_tokens: 512
    num_beams: 3
    temperature: 0.7

# ---------- Yi-VL -----------
yi-vl:
    max_new_tokens: 512
    num_beams: 3
    temperature: 0.7
    top_p: 0.9

# ---------- Phi-3-vision -----------
phi-3-vision-128k-instruct:
    max_new_tokens: 512
    num_beams: 3
    temperature: 0.7

# ---------- DeepSeek-VL -----------
deepseek-vl:
    max_new_tokens: 512
    # num_beams: 3
    # temperature: 0.7

deepseek-vl2:
    max_new_tokens: 512
    # num_beams: 3
    # temperature: 0.7

